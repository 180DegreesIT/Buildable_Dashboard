---
phase: 04-validation-go-live
plan: 02
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - server/src/services/PerformanceBenchmark.ts
  - server/src/services/ValidationService.ts
  - server/src/routes/validation.ts
  - client/src/components/admin/ValidationPanel.tsx
  - client/src/components/admin/AdminSettings.tsx
  - client/src/lib/validationApi.ts
  - client/src/components/dashboard/ExecutiveSummary.tsx
  - client/src/components/dashboard/FinancialDeepDive.tsx
  - client/src/components/dashboard/RegionalPerformance.tsx
  - client/src/components/targets/TargetManagement.tsx
autonomous: false

must_haves:
  truths:
    - "Performance benchmark measures warm page load time for all 4 dashboard pages and reports pass/fail against 2-second target"
    - "CSV round-trip test exports data as CSV, reimports via upload wizard logic, and confirms data matches original"
    - "Target workflow test creates a target, verifies it applies to the correct week, changes it, and verifies history is recorded"
    - "ValidationPanel in admin settings shows the full validation report with summary score and detailed breakdown"
    - "All 4 dashboard pages have a data-loaded attribute that signals when content is fully rendered"
  artifacts:
    - path: "server/src/services/PerformanceBenchmark.ts"
      provides: "Puppeteer-based page load timing for all dashboard pages"
      exports: ["PerformanceBenchmark"]
      min_lines: 80
    - path: "client/src/components/admin/ValidationPanel.tsx"
      provides: "Dashboard UI showing validation results with pass/fail indicators"
      min_lines: 100
    - path: "client/src/lib/validationApi.ts"
      provides: "API client for validation endpoints"
      min_lines: 20
  key_links:
    - from: "server/src/services/PerformanceBenchmark.ts"
      to: "http://localhost:4200"
      via: "Puppeteer page navigation"
      pattern: "puppeteer.*launch"
    - from: "client/src/components/admin/ValidationPanel.tsx"
      to: "/api/v1/validation/run"
      via: "fetch API call"
      pattern: "fetch.*validation"
    - from: "client/src/components/admin/AdminSettings.tsx"
      to: "client/src/components/admin/ValidationPanel.tsx"
      via: "component import and render"
      pattern: "ValidationPanel"
---

<objective>
Build performance benchmarking, CSV round-trip testing, target workflow verification, and the validation results dashboard panel. This completes the Phase 4 validation suite.

Purpose: Verify system performance meets the 2-second target, confirm CSV export/reimport integrity, validate target management workflow, and give users a visual way to see validation results.
Output: PerformanceBenchmark service, extended validation route with perf/round-trip/target tests, ValidationPanel UI component in admin settings.
</objective>

<execution_context>
@C:/Users/Dev180D/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Dev180D/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-validation-go-live/04-CONTEXT.md
@.planning/phases/04-validation-go-live/04-RESEARCH.md
@.planning/phases/04-validation-go-live/04-01-SUMMARY.md

# Key existing infrastructure
@server/src/services/PdfExportService.ts — Puppeteer launch pattern with PUPPETEER_EXECUTABLE_PATH
@server/src/services/ValidationService.ts — from plan 01, to be extended
@server/src/routes/validation.ts — from plan 01, to be extended
@server/src/routes/targets.ts — target CRUD endpoints
@server/src/services/TargetService.ts — target resolution and creation logic
@client/src/components/print/PrintLayout.tsx — data-print-ready attribute pattern
@client/src/components/admin/AdminSettings.tsx — admin settings page (add validation panel here)
@client/src/components/dashboard/ExecutiveSummary.tsx — needs data-loaded attribute
@client/src/components/dashboard/FinancialDeepDive.tsx — needs data-loaded attribute
@client/src/components/dashboard/RegionalPerformance.tsx — needs data-loaded attribute
@client/src/components/targets/TargetManagement.tsx — needs data-loaded attribute
@client/src/lib/csvExport.ts — CSV generation utilities
@server/src/routes/uploads.ts — CSV upload/import endpoint
</context>

<tasks>

<task type="auto">
  <name>Task 1: Build PerformanceBenchmark and add data-loaded signals to dashboard pages</name>
  <files>
    server/src/services/PerformanceBenchmark.ts
    client/src/components/dashboard/ExecutiveSummary.tsx
    client/src/components/dashboard/FinancialDeepDive.tsx
    client/src/components/dashboard/RegionalPerformance.tsx
    client/src/components/targets/TargetManagement.tsx
  </files>
  <action>
**Part A: Add `data-loaded` attribute to all 4 dashboard pages.**

Each dashboard component already has a loading state (LoadingSkeleton pattern). After data loads and renders, add `data-loaded="true"` to the outermost container div. Pattern:

```tsx
// In the main return after loading is complete:
<div data-loaded="true" className="...">
  {/* existing content */}
</div>
```

For each component:
- **ExecutiveSummary.tsx**: The component shows LoadingSkeleton when loading. After data is loaded (the main content renders), wrap the entire output div with `data-loaded="true"`.
- **FinancialDeepDive.tsx**: Same pattern -- add `data-loaded="true"` to the main container when data is rendered.
- **RegionalPerformance.tsx**: Same pattern.
- **TargetManagement.tsx**: Same pattern.

Only add the attribute when data is actually loaded (not during loading/empty states).

**Part B: Build PerformanceBenchmark service.**

Create `server/src/services/PerformanceBenchmark.ts` that measures warm page load times using Puppeteer.

```typescript
interface PageBenchmark {
  page: string;
  url: string;
  loadTimeMs: number;
  passed: boolean;     // loadTimeMs < 2000
  target: number;      // 2000
}

interface BenchmarkResult {
  runAt: string;
  allPassed: boolean;
  pages: PageBenchmark[];
}
```

**Implementation:**
1. Copy Puppeteer launch pattern from PdfExportService (headless, PUPPETEER_EXECUTABLE_PATH support, --no-sandbox args)
2. Navigate to each dashboard page URL on `http://localhost:{CLIENT_PORT || 4200}`
3. **Warm load methodology:** Navigate to the page TWICE. First load warms caches. Measure the SECOND load only.
4. Wait for `[data-loaded="true"]` attribute to appear using `page.waitForSelector('[data-loaded="true"]', { timeout: 15000 })`
5. Measure time from navigation start to data-loaded signal
6. Test 4 pages: Executive Summary (`/` or root with executive_summary active), Financial Deep Dive, Regional Performance, Target Management

**Page URLs:**
The app uses client-side state routing (not URL routing). To test each page, navigate to the root URL and then use Puppeteer to click the sidebar navigation items. OR use a simpler approach: add query parameters that the app can read to set the initial page.

Actually, the simplest approach: use the **print routes** which render standalone pages. These test the same data-fetching and rendering pipeline:
- `http://localhost:4200/#/print/executive-summary?week=2025-01-25`
- `http://localhost:4200/#/print/financial?week=2025-01-25`
- `http://localhost:4200/#/print/regional?week=2025-01-25`
- `http://localhost:4200/#/print/targets?week=2025-01-25`

BUT: these are print variants, not the actual dashboard pages. For accurate benchmarking, use the print pages (they fetch the same data from the same API endpoints) and note this in the results. The print pages already have the `data-print-ready` attribute.

So actually use `page.waitForSelector('[data-print-ready="true"]')` for print pages.

**Alternative (preferred):** Navigate to `http://localhost:4200/` and use Puppeteer's `page.evaluate()` to programmatically trigger page navigation by dispatching custom events or directly setting state. This is complex.

**Final decision:** Use print routes for benchmarking. They exercise the same API calls and data rendering. Add a note in the result that print routes are used as a proxy. The `data-print-ready` signal from PrintLayout.tsx already exists.

Use week ending from the latest checkpoint week in reference-values.json.

5. Close browser after all pages measured
6. Return BenchmarkResult

**Console output:** Print each page result with timing and pass/fail.
  </action>
  <verify>
1. All 4 dashboard components have `data-loaded="true"` attribute in their rendered output
2. PerformanceBenchmark.ts compiles without errors
3. The service exports a `runBenchmark()` function returning BenchmarkResult
  </verify>
  <done>
All 4 dashboard pages signal data-loaded state via HTML attribute. PerformanceBenchmark service measures warm page load for each page using Puppeteer and reports pass/fail against 2-second target.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add CSV round-trip test, target workflow test, and extend validation route</name>
  <files>
    server/src/services/ValidationService.ts
    server/src/routes/validation.ts
  </files>
  <action>
**Part A: Add CSV round-trip test to ValidationService.**

Add a `runCsvRoundTrip()` method that:
1. Pick one checkpoint week from reference data
2. Fetch the financial data for that week from `GET /api/v1/dashboard/financial-deep-dive?weekEnding={date}`
3. Generate a CSV string from the P&L weekly data using the same column format as the CSV export (match csvExport.ts format)
4. Parse the CSV string back (split by commas, handle escaping)
5. Compare parsed values against the original API response values
6. Return pass/fail result with details

This tests that the export format can be read back accurately. It does NOT actually reimport via the upload wizard (that would modify the database). Instead, it verifies the CSV serialisation/deserialisation round-trip is lossless for numeric values.

Result structure:
```typescript
interface RoundTripResult {
  weekEnding: string;
  fields: Array<{
    field: string;
    original: number;
    exported: string;
    reimported: number;
    passed: boolean;
  }>;
  allPassed: boolean;
}
```

**Part B: Add target workflow test to ValidationService.**

Add a `runTargetWorkflowTest()` method that:
1. Create a test target via `POST /api/v1/targets` with:
   - targetType: 'breakeven' (unlikely to conflict with real data)
   - amount: 99999.99
   - effectiveFrom: '2020-01-04' (a Saturday far in the past, won't affect real data)
   - setBy: 'validation-test'
   - notes: 'Automated validation test - safe to delete'
2. Verify the target was created: `GET /api/v1/targets/current?weekEnding=2020-01-04` should include it
3. Update the target via `PUT /api/v1/targets/:id` with new amount 88888.88
4. Verify the update applied: fetch current targets again, check amount is 88888.88
5. Verify history was recorded: `GET /api/v1/targets/:id/history` should show the change
6. Clean up: delete the test target if a delete endpoint exists, or note it needs manual cleanup

Result structure:
```typescript
interface TargetWorkflowResult {
  steps: Array<{
    step: string;
    passed: boolean;
    detail: string;
  }>;
  allPassed: boolean;
}
```

**Part C: Extend validation route.**

Add endpoints:
- `GET /api/v1/validation/benchmark` — Runs PerformanceBenchmark and returns BenchmarkResult
- `GET /api/v1/validation/full` — Runs ALL validation (data comparison + CSV round-trip + target workflow + performance benchmark). Returns a combined result:

```typescript
interface FullValidationResult {
  dataValidation: ValidationResult;      // From plan 01
  csvRoundTrip: RoundTripResult;
  targetWorkflow: TargetWorkflowResult;
  performance: BenchmarkResult;
  overallPassed: boolean;
  summary: string; // e.g. "Data: 47/50, CSV: PASS, Targets: PASS, Perf: 4/4"
}
```

The /full endpoint runs tests sequentially (data first, then CSV, then targets, then perf) and streams progress to console. Total runtime may be 15-30 seconds due to Puppeteer.

**Console output for /full:**
```
=== VALIDATION SUITE ===
[1/4] Data validation... 47/50 passed
[2/4] CSV round-trip... PASSED
[3/4] Target workflow... PASSED (5/5 steps)
[4/4] Performance benchmark...
  Executive Summary: 850ms [PASS]
  Financial: 1200ms [PASS]
  Regional: 780ms [PASS]
  Targets: 650ms [PASS]

OVERALL: PASSED (47/50 data, CSV OK, targets OK, perf 4/4)
```
  </action>
  <verify>
1. `curl http://localhost:6001/api/v1/validation/benchmark` returns benchmark results for 4 pages
2. `curl http://localhost:6001/api/v1/validation/full` returns the combined validation result
3. Server console shows detailed progress during full validation run
4. Target workflow test creates, updates, and verifies a target without affecting real data
5. CSV round-trip test confirms numeric values survive export/reimport
  </verify>
  <done>
CSV round-trip test verifies export/parse losslessness. Target workflow test verifies create/update/history cycle. Performance benchmark measures all 4 pages against 2-second target. Full validation endpoint combines all tests into a single comprehensive report.
  </done>
</task>

<task type="auto">
  <name>Task 3: Build ValidationPanel UI in admin settings</name>
  <files>
    client/src/components/admin/ValidationPanel.tsx
    client/src/components/admin/AdminSettings.tsx
    client/src/lib/validationApi.ts
  </files>
  <action>
**Part A: Create `client/src/lib/validationApi.ts`**

API client for validation endpoints:
```typescript
export async function runFullValidation(): Promise<FullValidationResult> { ... }
export async function runDataValidation(): Promise<ValidationResult> { ... }
export async function runBenchmark(): Promise<BenchmarkResult> { ... }
export async function getReference(): Promise<ReferenceData> { ... }
```

Use the same fetch pattern as other API clients (e.g. dashboardApi.ts). Base URL from `api.ts` module.

Define TypeScript interfaces matching the server response types (ValidationResult, BenchmarkResult, FullValidationResult, etc.).

**Part B: Create `client/src/components/admin/ValidationPanel.tsx`**

Build a validation results panel that displays in the admin settings page. Follow Asana design language.

Layout:
1. **Header section:** "System Validation" title with a "Run Full Validation" button (primary colour #4573D2). Show "Run Data Only" and "Run Performance Only" as secondary buttons.
2. **Summary bar:** When results exist, show a summary like "47/50 data checks passed | CSV: PASS | Targets: PASS | Performance: 4/4 pages < 2s". Use green (#6AAF50) for pass, red (#D94F4F) for fail.
3. **Tabs or sections** for each validation category:
   - **Data Validation:** Table with columns: Check ID, Category, Week, Field, Expected, Actual, Difference, Status (green check or red X). Group by category. Failed checks highlighted in light red background.
   - **CSV Round-Trip:** Simple pass/fail card showing field-level comparison if failed.
   - **Target Workflow:** Step-by-step list with green/red indicators.
   - **Performance:** Card per page showing load time with a progress bar (green if < 2s, red if > 2s).
4. **Loading state:** While validation is running, show a spinner with "Running validation... this may take 15-30 seconds".
5. **Empty state:** Before first run, show "Click 'Run Full Validation' to verify system accuracy and performance."

**Styling:**
- White card backgrounds with subtle shadow (matching existing admin components)
- 8px border radius, 24px padding
- Use existing Tailwind classes consistent with AdminSettings.tsx
- Status badges: green bg-green-100 text-green-800, red bg-red-100 text-red-800
- Table rows: alternating bg-gray-50/white, failed rows bg-red-50

**Part C: Add ValidationPanel to AdminSettings.tsx**

Import ValidationPanel and add it as a new section at the bottom of the admin settings page. Use the same card/section pattern as BrandingSection, AlertThresholds, etc. Only show for development/admin users (the existing admin settings page is already restricted by permission).

Add it after the existing sections with a section gap (32px) to match the spacing pattern.
  </action>
  <verify>
1. Client compiles without TypeScript errors (`npm run build` in client directory or `npx tsc --noEmit`)
2. ValidationPanel renders in admin settings page
3. "Run Full Validation" button triggers API call and displays results
4. Failed checks are visually distinct (red highlighting)
5. Performance results show load times with pass/fail indicators
  </verify>
  <done>
ValidationPanel is visible in admin settings, can trigger validation runs, and displays structured results with colour-coded pass/fail indicators for all four validation categories. Summary bar provides at-a-glance status.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Complete Phase 4 validation system: reference value extraction, data comparison across all checkpoint weeks, CSV round-trip test, target workflow test, Puppeteer performance benchmark, and dashboard UI panel showing all results.
  </what-built>
  <how-to-verify>
1. Start the dev server: `npm run dev`
2. Navigate to Admin Settings page in the dashboard
3. Scroll to the "System Validation" section at the bottom
4. Click "Run Full Validation" and wait for results (15-30 seconds)
5. Verify:
   - Data validation shows pass/fail per check with expected vs actual values
   - Week 30 Net Profit shows ~$62,210.45
   - CSV round-trip shows PASS
   - Target workflow shows all steps PASS
   - Performance shows all 4 pages under 2 seconds
6. Check terminal/console for coloured validation output
7. Try `curl http://localhost:6001/api/v1/validation/full` to see raw JSON response
  </how-to-verify>
  <resume-signal>Type "approved" or describe any issues with the validation results</resume-signal>
</task>

</tasks>

<verification>
1. All 6 VALD requirements are addressed:
   - VALD-01: Week 30 KPI values compared against Excel reference
   - VALD-02: Regional team figures compared for Week 30
   - VALD-03: Lead source data compared for Week 30
   - VALD-04: CSV round-trip test (export → parse → compare)
   - VALD-05: Target management workflow test (create → verify → change → history)
   - VALD-06: Executive Summary (and all pages) load time measured against 2-second target
2. Validation results visible in both terminal console AND dashboard UI
3. Summary score format: "X/Y checks passed (Z%)"
4. All 4 dashboard pages have data-loaded render signal
5. Performance uses warm load measurement (Puppeteer navigates twice, measures second load)
</verification>

<success_criteria>
- Full validation suite runs end-to-end without errors
- Data validation checks pass for known Week 30 reference values
- CSV round-trip produces lossless numeric values
- Target create/update/history workflow completes successfully
- All 4 dashboard pages load under 2 seconds on warm load
- ValidationPanel displays clear, colour-coded results in admin settings
- Terminal output shows comprehensive validation summary
</success_criteria>

<output>
After completion, create `.planning/phases/04-validation-go-live/04-02-SUMMARY.md`
</output>
